{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit 12 - Tales from the Crypto\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Sentiment Analysis\n",
    "\n",
    "Use the [newsapi](https://newsapi.org/) to pull the latest news articles for Bitcoin and Ethereum and create a DataFrame of sentiment scores for each coin.\n",
    "\n",
    "Use descriptive statistics to answer the following questions:\n",
    "1. Which coin had the highest mean positive score?\n",
    "2. Which coin had the highest negative score?\n",
    "3. Which coin had the highest positive score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\edelb\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Initial imports\n",
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import nltk as nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9a2d0207baf44931bde4e6ab90344986\n"
     ]
    }
   ],
   "source": [
    "# Read your api key environment variable\n",
    "load_dotenv(\"../Starter_Code/.env\")\n",
    "api_key = os.getenv(\"news_api\")\n",
    "print(api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a newsapi client\n",
    "from newsapi import NewsApiClient\n",
    "newsapi = NewsApiClient(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the Bitcoin news articles\n",
    "btc_news = newsapi.get_everything(\n",
    "    q=\"bitcoin\",\n",
    "    language=\"en\",\n",
    "    sort_by=\"relevancy\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the Ethereum news articles\n",
    "eth_news = newsapi.get_everything(\n",
    "    q=\"ethereum\",\n",
    "    language=\"en\",\n",
    "    sort_by=\"relevancy\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>compound</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-05-10</td>\n",
       "      <td>Now, even though there are a number of women-f...</td>\n",
       "      <td>0.0772</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-05-04</td>\n",
       "      <td>A Bitcoin mining site powered by otherwise los...</td>\n",
       "      <td>-0.0516</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-05-02</td>\n",
       "      <td>Warren Buffett has always been a bitcoin skept...</td>\n",
       "      <td>-0.3269</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-05-16</td>\n",
       "      <td>As a kid, I remember when my father tried to u...</td>\n",
       "      <td>0.3818</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-05-09</td>\n",
       "      <td>Image source, Getty Images\\r\\nThe value of Bit...</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                                               text  compound  \\\n",
       "0  2022-05-10  Now, even though there are a number of women-f...    0.0772   \n",
       "1  2022-05-04  A Bitcoin mining site powered by otherwise los...   -0.0516   \n",
       "2  2022-05-02  Warren Buffett has always been a bitcoin skept...   -0.3269   \n",
       "3  2022-05-16  As a kid, I remember when my father tried to u...    0.3818   \n",
       "4  2022-05-09  Image source, Getty Images\\r\\nThe value of Bit...    0.3400   \n",
       "\n",
       "   positive  negative  neutral  \n",
       "0     0.036     0.000    0.964  \n",
       "1     0.056     0.061    0.882  \n",
       "2     0.085     0.143    0.772  \n",
       "3     0.114     0.052    0.833  \n",
       "4     0.072     0.000    0.928  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the Bitcoin sentiment scores DataFrame\n",
    "btc_sentiments = []\n",
    "\n",
    "for article in btc_news[\"articles\"]:\n",
    "    try:\n",
    "        text = article[\"content\"]\n",
    "        date = article[\"publishedAt\"][:10]\n",
    "        sentiment = analyzer.polarity_scores(text)\n",
    "        compound = sentiment[\"compound\"]\n",
    "        pos = sentiment[\"pos\"]\n",
    "        neu = sentiment[\"neu\"]\n",
    "        neg = sentiment[\"neg\"]\n",
    "        \n",
    "        btc_sentiments.append({\n",
    "            \"text\": text,\n",
    "            \"date\": date,\n",
    "            \"compound\": compound,\n",
    "            \"positive\": pos,\n",
    "            \"negative\": neg,\n",
    "            \"neutral\": neu\n",
    "            \n",
    "        })\n",
    "        \n",
    "    except AttributeError:\n",
    "        pass\n",
    "    \n",
    "# Create DataFrame\n",
    "btc_df = pd.DataFrame(btc_sentiments)\n",
    "\n",
    "# Reorder DataFrame columns\n",
    "cols = [\"date\", \"text\", \"compound\", \"positive\", \"negative\", \"neutral\"]\n",
    "btc_df = btc_df[cols]\n",
    "\n",
    "btc_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>compound</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-05-10</td>\n",
       "      <td>Meta has revealed more of how NFTs will work o...</td>\n",
       "      <td>0.6486</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-05-23</td>\n",
       "      <td>GameStop has officially thrown itself headlong...</td>\n",
       "      <td>-0.1027</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-05-02</td>\n",
       "      <td>A multi-billion dollar cryptocurrency company ...</td>\n",
       "      <td>-0.2263</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-05-04</td>\n",
       "      <td>When Bored Ape Yacht Club creators Yuga Labs a...</td>\n",
       "      <td>-0.2732</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-05-23</td>\n",
       "      <td>GameStop is going all-in on crypto. The video ...</td>\n",
       "      <td>0.1280</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                                               text  compound  \\\n",
       "0  2022-05-10  Meta has revealed more of how NFTs will work o...    0.6486   \n",
       "1  2022-05-23  GameStop has officially thrown itself headlong...   -0.1027   \n",
       "2  2022-05-02  A multi-billion dollar cryptocurrency company ...   -0.2263   \n",
       "3  2022-05-04  When Bored Ape Yacht Club creators Yuga Labs a...   -0.2732   \n",
       "4  2022-05-23  GameStop is going all-in on crypto. The video ...    0.1280   \n",
       "\n",
       "   positive  negative  neutral  \n",
       "0     0.135     0.000    0.865  \n",
       "1     0.000     0.040    0.960  \n",
       "2     0.046     0.075    0.879  \n",
       "3     0.000     0.055    0.945  \n",
       "4     0.046     0.000    0.954  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the Ethereum sentiment scores DataFrame\n",
    "eth_sentiments = []\n",
    "\n",
    "for article in eth_news[\"articles\"]:\n",
    "    try:\n",
    "        text = article[\"content\"]\n",
    "        date = article[\"publishedAt\"][:10]\n",
    "        sentiment = analyzer.polarity_scores(text)\n",
    "        compound = sentiment[\"compound\"]\n",
    "        pos = sentiment[\"pos\"]\n",
    "        neu = sentiment[\"neu\"]\n",
    "        neg = sentiment[\"neg\"]\n",
    "        \n",
    "        eth_sentiments.append({\n",
    "            \"text\": text,\n",
    "            \"date\": date,\n",
    "            \"compound\": compound,\n",
    "            \"positive\": pos,\n",
    "            \"negative\": neg,\n",
    "            \"neutral\": neu\n",
    "            \n",
    "        })\n",
    "        \n",
    "    except AttributeError:\n",
    "        pass\n",
    "    \n",
    "# Create DataFrame\n",
    "eth_df = pd.DataFrame(eth_sentiments)\n",
    "\n",
    "# Reorder DataFrame columns\n",
    "cols = [\"date\", \"text\", \"compound\", \"positive\", \"negative\", \"neutral\"]\n",
    "eth_df = eth_df[cols]\n",
    "\n",
    "eth_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>compound</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.119220</td>\n",
       "      <td>0.063350</td>\n",
       "      <td>0.084900</td>\n",
       "      <td>0.851800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.404397</td>\n",
       "      <td>0.060985</td>\n",
       "      <td>0.075734</td>\n",
       "      <td>0.100743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.859300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.557000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.386825</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.057250</td>\n",
       "      <td>0.827000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.284600</td>\n",
       "      <td>0.055000</td>\n",
       "      <td>0.071500</td>\n",
       "      <td>0.878000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.156025</td>\n",
       "      <td>0.085000</td>\n",
       "      <td>0.103750</td>\n",
       "      <td>0.923000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.750600</td>\n",
       "      <td>0.202000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.964000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        compound   positive   negative    neutral\n",
       "count  20.000000  20.000000  20.000000  20.000000\n",
       "mean   -0.119220   0.063350   0.084900   0.851800\n",
       "std     0.404397   0.060985   0.075734   0.100743\n",
       "min    -0.859300   0.000000   0.000000   0.557000\n",
       "25%    -0.386825   0.000000   0.057250   0.827000\n",
       "50%    -0.284600   0.055000   0.071500   0.878000\n",
       "75%     0.156025   0.085000   0.103750   0.923000\n",
       "max     0.750600   0.202000   0.300000   0.964000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Describe the Bitcoin Sentiment\n",
    "btc_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>compound</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.088800</td>\n",
       "      <td>0.032800</td>\n",
       "      <td>0.048600</td>\n",
       "      <td>0.918700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.343530</td>\n",
       "      <td>0.051042</td>\n",
       "      <td>0.043472</td>\n",
       "      <td>0.051321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.690800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.822000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.284450</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.875500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.153100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.935000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.045025</td>\n",
       "      <td>0.051750</td>\n",
       "      <td>0.069000</td>\n",
       "      <td>0.955000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.690800</td>\n",
       "      <td>0.178000</td>\n",
       "      <td>0.178000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        compound   positive   negative    neutral\n",
       "count  20.000000  20.000000  20.000000  20.000000\n",
       "mean   -0.088800   0.032800   0.048600   0.918700\n",
       "std     0.343530   0.051042   0.043472   0.051321\n",
       "min    -0.690800   0.000000   0.000000   0.822000\n",
       "25%    -0.284450   0.000000   0.000000   0.875500\n",
       "50%    -0.153100   0.000000   0.050000   0.935000\n",
       "75%     0.045025   0.051750   0.069000   0.955000\n",
       "max     0.690800   0.178000   0.178000   1.000000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Describe the Ethereum Sentiment\n",
    "eth_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions:\n",
    "\n",
    "Q: Which coin had the highest mean positive score?\n",
    "\n",
    "A: Bitcoin \n",
    "\n",
    "Q: Which coin had the highest compound score?\n",
    "\n",
    "A: Bitcoin\n",
    "\n",
    "Q. Which coin had the highest positive score?\n",
    "\n",
    "A: Bitcoin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Natural Language Processing\n",
    "---\n",
    "###   Tokenizer\n",
    "\n",
    "In this section, you will use NLTK and Python to tokenize the text for each coin. Be sure to:\n",
    "1. Lowercase each word.\n",
    "2. Remove Punctuation.\n",
    "3. Remove Stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from string import punctuation\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Create a list of stopwords\n",
    "sw = set(stopwords.words('english'))\n",
    "\n",
    "# Expand the default stopwords list if necessary\n",
    "sw_addon = {'a', 'of', 'to','the','it','in'}\n",
    "sw = sw.union(sw_addon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete the tokenizer function\n",
    "def tokenizer(text):\n",
    "    \"\"\"Tokenizes text.\"\"\"\n",
    "    \n",
    "    # Create a tokenized list of the words\n",
    "    words = word_tokenize(text) \n",
    "    \n",
    "    # Remove the punctuation from text\n",
    "    words = list(filter(lambda t: t not in punctuation, words))    \n",
    "    \n",
    "    # Lemmatize words into root words\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in words]\n",
    "   \n",
    "    # Convert the words to lowercase\n",
    "    words = list(filter(lambda w: w.lower(), words))    \n",
    "    \n",
    "    # Remove the stop words\n",
    "    words = list(filter(lambda t: t.lower() not in sw, words))\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>compound</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-05-10</td>\n",
       "      <td>Now, even though there are a number of women-f...</td>\n",
       "      <td>0.0772</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.964</td>\n",
       "      <td>[Now, even, though, there, are, a, number, of,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-05-04</td>\n",
       "      <td>A Bitcoin mining site powered by otherwise los...</td>\n",
       "      <td>-0.0516</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.882</td>\n",
       "      <td>[A, Bitcoin, mining, site, powered, by, otherw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-05-02</td>\n",
       "      <td>Warren Buffett has always been a bitcoin skept...</td>\n",
       "      <td>-0.3269</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.772</td>\n",
       "      <td>[Warren, Buffett, ha, always, been, a, bitcoin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-05-16</td>\n",
       "      <td>As a kid, I remember when my father tried to u...</td>\n",
       "      <td>0.3818</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.833</td>\n",
       "      <td>[As, a, kid, I, remember, when, my, father, tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-05-09</td>\n",
       "      <td>Image source, Getty Images\\r\\nThe value of Bit...</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.928</td>\n",
       "      <td>[Image, source, Getty, Images, The, value, of,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                                               text  compound  \\\n",
       "0  2022-05-10  Now, even though there are a number of women-f...    0.0772   \n",
       "1  2022-05-04  A Bitcoin mining site powered by otherwise los...   -0.0516   \n",
       "2  2022-05-02  Warren Buffett has always been a bitcoin skept...   -0.3269   \n",
       "3  2022-05-16  As a kid, I remember when my father tried to u...    0.3818   \n",
       "4  2022-05-09  Image source, Getty Images\\r\\nThe value of Bit...    0.3400   \n",
       "\n",
       "   positive  negative  neutral  \\\n",
       "0     0.036     0.000    0.964   \n",
       "1     0.056     0.061    0.882   \n",
       "2     0.085     0.143    0.772   \n",
       "3     0.114     0.052    0.833   \n",
       "4     0.072     0.000    0.928   \n",
       "\n",
       "                                              tokens  \n",
       "0  [Now, even, though, there, are, a, number, of,...  \n",
       "1  [A, Bitcoin, mining, site, powered, by, otherw...  \n",
       "2  [Warren, Buffett, ha, always, been, a, bitcoin...  \n",
       "3  [As, a, kid, I, remember, when, my, father, tr...  \n",
       "4  [Image, source, Getty, Images, The, value, of,...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new tokens column for Bitcoin\n",
    "btc_df[\"tokens\"] = btc_df.text.apply(tokenizer)\n",
    "btc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>compound</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-05-10</td>\n",
       "      <td>Meta has revealed more of how NFTs will work o...</td>\n",
       "      <td>0.6486</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.865</td>\n",
       "      <td>[Meta, ha, revealed, more, of, how, NFTs, will...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-05-23</td>\n",
       "      <td>GameStop has officially thrown itself headlong...</td>\n",
       "      <td>-0.1027</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.960</td>\n",
       "      <td>[GameStop, ha, officially, thrown, itself, hea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-05-02</td>\n",
       "      <td>A multi-billion dollar cryptocurrency company ...</td>\n",
       "      <td>-0.2263</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.879</td>\n",
       "      <td>[A, multi-billion, dollar, cryptocurrency, com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-05-04</td>\n",
       "      <td>When Bored Ape Yacht Club creators Yuga Labs a...</td>\n",
       "      <td>-0.2732</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.945</td>\n",
       "      <td>[When, Bored, Ape, Yacht, Club, creator, Yuga,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-05-23</td>\n",
       "      <td>GameStop is going all-in on crypto. The video ...</td>\n",
       "      <td>0.1280</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.954</td>\n",
       "      <td>[GameStop, is, going, all-in, on, crypto, The,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                                               text  compound  \\\n",
       "0  2022-05-10  Meta has revealed more of how NFTs will work o...    0.6486   \n",
       "1  2022-05-23  GameStop has officially thrown itself headlong...   -0.1027   \n",
       "2  2022-05-02  A multi-billion dollar cryptocurrency company ...   -0.2263   \n",
       "3  2022-05-04  When Bored Ape Yacht Club creators Yuga Labs a...   -0.2732   \n",
       "4  2022-05-23  GameStop is going all-in on crypto. The video ...    0.1280   \n",
       "\n",
       "   positive  negative  neutral  \\\n",
       "0     0.135     0.000    0.865   \n",
       "1     0.000     0.040    0.960   \n",
       "2     0.046     0.075    0.879   \n",
       "3     0.000     0.055    0.945   \n",
       "4     0.046     0.000    0.954   \n",
       "\n",
       "                                              tokens  \n",
       "0  [Meta, ha, revealed, more, of, how, NFTs, will...  \n",
       "1  [GameStop, ha, officially, thrown, itself, hea...  \n",
       "2  [A, multi-billion, dollar, cryptocurrency, com...  \n",
       "3  [When, Bored, Ape, Yacht, Club, creator, Yuga,...  \n",
       "4  [GameStop, is, going, all-in, on, crypto, The,...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new tokens column for Ethereum\n",
    "eth_df[\"tokens\"] = eth_df.text.apply(tokenizer)\n",
    "eth_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NGrams and Frequency Analysis\n",
    "\n",
    "In this section you will look at the ngrams and word frequency for each coin. \n",
    "\n",
    "1. Use NLTK to produce the n-grams for N = 2. \n",
    "2. List the top 10 words for each coin. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from nltk import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('a', 'new'), 6),\n",
       " (('for', 'the'), 5),\n",
       " (('the', 'world'), 5),\n",
       " (('world', \"'s\"), 4),\n",
       " (('Reuters', 'Bitcoin'), 4),\n",
       " (('char', 'May'), 4),\n",
       " (('in', 'the'), 4),\n",
       " (('the', 'only'), 3),\n",
       " (('it', 'previous'), 3),\n",
       " (('previous', 'close'), 3)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate the Bitcoin N-grams where N=2\n",
    "N = 2\n",
    "btc_grams = ngrams(tokenizer(btc_df.text.str.cat()), N)\n",
    "Counter(btc_grams).most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('the', 'world'), 4),\n",
       " (('world', \"'s\"), 4),\n",
       " (('char', 'May'), 3),\n",
       " (('Reuters', 'Bitcoin'), 3),\n",
       " (('it', 'previous'), 3),\n",
       " (('previous', 'close'), 3),\n",
       " (('close', 'Bitcoin'), 3),\n",
       " (('Bitcoin', 'the'), 3),\n",
       " ((\"'s\", 'biggest'), 3),\n",
       " (('biggest', 'and'), 3)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate the Ethereum N-grams where N=2\n",
    "N = 2\n",
    "eth_grams = ngrams(tokenizer(eth_df.text.str.cat()), N)\n",
    "Counter(eth_grams).most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function token_count generates the top 10 words for a given coin\n",
    "def token_count(tokens, N=3):\n",
    "    \"\"\"Returns the top N tokens from the frequency count\"\"\"\n",
    "    return Counter(tokens).most_common(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 31),\n",
       " ('a', 21),\n",
       " ('to', 21),\n",
       " ('char', 19),\n",
       " ('of', 13),\n",
       " ('in', 11),\n",
       " ('Bitcoin', 10),\n",
       " ('it', 10),\n",
       " (\"'s\", 10),\n",
       " ('cryptocurrency', 9)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use token_count to get the top 10 words for Bitcoin\n",
    "btc_tokens = tokenizer(btc_df.text.str.cat())\n",
    "token_count(btc_tokens, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('to', 26),\n",
       " ('a', 24),\n",
       " ('the', 23),\n",
       " ('char', 20),\n",
       " ('it', 16),\n",
       " ('cryptocurrency', 12),\n",
       " ('of', 11),\n",
       " ('The', 10),\n",
       " ('on', 9),\n",
       " ('Bitcoin', 9)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use token_count to get the top 10 words for Ethereum\n",
    "eth_tokens = tokenizer(eth_df.text.str.cat())\n",
    "token_count(eth_tokens, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Clouds\n",
    "\n",
    "In this section, you will generate word clouds for each coin to summarize the news for each coin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.figsize'] = [20.0, 10.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [26]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Generate the Bitcoin word cloud\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m btc_wordcloud \u001b[38;5;241m=\u001b[39m \u001b[43mWordCloud\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolormap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRdYlBu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbtc_tokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(wordcloud)\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39maxis(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moff\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\wordcloud\\wordcloud.py:632\u001b[0m, in \u001b[0;36mWordCloud.generate\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    617\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate\u001b[39m(\u001b[38;5;28mself\u001b[39m, text):\n\u001b[0;32m    618\u001b[0m     \u001b[38;5;124;03m\"\"\"Generate wordcloud from text.\u001b[39;00m\n\u001b[0;32m    619\u001b[0m \n\u001b[0;32m    620\u001b[0m \u001b[38;5;124;03m    The input \"text\" is expected to be a natural text. If you pass a sorted\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;124;03m    self\u001b[39;00m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 632\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_from_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\wordcloud\\wordcloud.py:613\u001b[0m, in \u001b[0;36mWordCloud.generate_from_text\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    596\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_from_text\u001b[39m(\u001b[38;5;28mself\u001b[39m, text):\n\u001b[0;32m    597\u001b[0m     \u001b[38;5;124;03m\"\"\"Generate wordcloud from text.\u001b[39;00m\n\u001b[0;32m    598\u001b[0m \n\u001b[0;32m    599\u001b[0m \u001b[38;5;124;03m    The input \"text\" is expected to be a natural text. If you pass a sorted\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    611\u001b[0m \u001b[38;5;124;03m    self\u001b[39;00m\n\u001b[0;32m    612\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 613\u001b[0m     words \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_from_frequencies(words)\n\u001b[0;32m    615\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\wordcloud\\wordcloud.py:575\u001b[0m, in \u001b[0;36mWordCloud.process_text\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    572\u001b[0m pattern \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw[\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]*\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_word_length \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw[\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]+\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    573\u001b[0m regexp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregexp \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregexp \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m pattern\n\u001b[1;32m--> 575\u001b[0m words \u001b[38;5;241m=\u001b[39m \u001b[43mre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfindall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mregexp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    576\u001b[0m \u001b[38;5;66;03m# remove 's\u001b[39;00m\n\u001b[0;32m    577\u001b[0m words \u001b[38;5;241m=\u001b[39m [word[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m word\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m word\n\u001b[0;32m    578\u001b[0m          \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m words]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\re.py:241\u001b[0m, in \u001b[0;36mfindall\u001b[1;34m(pattern, string, flags)\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfindall\u001b[39m(pattern, string, flags\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m    234\u001b[0m     \u001b[38;5;124;03m\"\"\"Return a list of all non-overlapping matches in the string.\u001b[39;00m\n\u001b[0;32m    235\u001b[0m \n\u001b[0;32m    236\u001b[0m \u001b[38;5;124;03m    If one or more capturing groups are present in the pattern, return\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    239\u001b[0m \n\u001b[0;32m    240\u001b[0m \u001b[38;5;124;03m    Empty matches are included in the result.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfindall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstring\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "# Generate the Bitcoin word cloud\n",
    "btc_wordcloud = WordCloud(colormap=\"RdYlBu\").generate(btc_tokens)\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "fontdict = {\"fontsize\": 20, \"fontweight\": \"bold\"}\n",
    "plt.title(\"Money News Word Cloud\", fontdict=fontdict)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [27]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Generate the Ethereum word cloud\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m eth_wordcloud \u001b[38;5;241m=\u001b[39m \u001b[43mWordCloud\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolormap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRdYlBu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43meth_tokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(wordcloud)\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39maxis(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moff\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\wordcloud\\wordcloud.py:632\u001b[0m, in \u001b[0;36mWordCloud.generate\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    617\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate\u001b[39m(\u001b[38;5;28mself\u001b[39m, text):\n\u001b[0;32m    618\u001b[0m     \u001b[38;5;124;03m\"\"\"Generate wordcloud from text.\u001b[39;00m\n\u001b[0;32m    619\u001b[0m \n\u001b[0;32m    620\u001b[0m \u001b[38;5;124;03m    The input \"text\" is expected to be a natural text. If you pass a sorted\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;124;03m    self\u001b[39;00m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 632\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_from_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\wordcloud\\wordcloud.py:613\u001b[0m, in \u001b[0;36mWordCloud.generate_from_text\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    596\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_from_text\u001b[39m(\u001b[38;5;28mself\u001b[39m, text):\n\u001b[0;32m    597\u001b[0m     \u001b[38;5;124;03m\"\"\"Generate wordcloud from text.\u001b[39;00m\n\u001b[0;32m    598\u001b[0m \n\u001b[0;32m    599\u001b[0m \u001b[38;5;124;03m    The input \"text\" is expected to be a natural text. If you pass a sorted\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    611\u001b[0m \u001b[38;5;124;03m    self\u001b[39;00m\n\u001b[0;32m    612\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 613\u001b[0m     words \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_from_frequencies(words)\n\u001b[0;32m    615\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\wordcloud\\wordcloud.py:575\u001b[0m, in \u001b[0;36mWordCloud.process_text\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    572\u001b[0m pattern \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw[\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]*\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_word_length \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw[\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]+\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    573\u001b[0m regexp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregexp \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregexp \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m pattern\n\u001b[1;32m--> 575\u001b[0m words \u001b[38;5;241m=\u001b[39m \u001b[43mre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfindall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mregexp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    576\u001b[0m \u001b[38;5;66;03m# remove 's\u001b[39;00m\n\u001b[0;32m    577\u001b[0m words \u001b[38;5;241m=\u001b[39m [word[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m word\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m word\n\u001b[0;32m    578\u001b[0m          \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m words]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\re.py:241\u001b[0m, in \u001b[0;36mfindall\u001b[1;34m(pattern, string, flags)\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfindall\u001b[39m(pattern, string, flags\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m    234\u001b[0m     \u001b[38;5;124;03m\"\"\"Return a list of all non-overlapping matches in the string.\u001b[39;00m\n\u001b[0;32m    235\u001b[0m \n\u001b[0;32m    236\u001b[0m \u001b[38;5;124;03m    If one or more capturing groups are present in the pattern, return\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    239\u001b[0m \n\u001b[0;32m    240\u001b[0m \u001b[38;5;124;03m    Empty matches are included in the result.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfindall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstring\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "# Generate the Ethereum word cloud\n",
    "eth_wordcloud = WordCloud(colormap=\"RdYlBu\").generate(eth_tokens)\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "fontdict = {\"fontsize\": 20, \"fontweight\": \"bold\"}\n",
    "plt.title(\"Money News Word Cloud\", fontdict=fontdict)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Named Entity Recognition\n",
    "\n",
    "In this section, you will build a named entity recognition model for both Bitcoin and Ethereum, then visualize the tags using SpaCy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [28]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m displacy\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'spacy'"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the language model for SpaCy\n",
    " !python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the spaCy model\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Bitcoin NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all of the Bitcoin text together\n",
    "btc_txt = btc_df.text.str.cat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nlp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [31]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Run the NER processor on all of the text\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m doc \u001b[38;5;241m=\u001b[39m \u001b[43mnlp\u001b[49m(btc_txt)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Add a title to the document\u001b[39;00m\n\u001b[0;32m      5\u001b[0m doc\u001b[38;5;241m.\u001b[39muser_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBTC NER\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nlp' is not defined"
     ]
    }
   ],
   "source": [
    "# Run the NER processor on all of the text\n",
    "doc = nlp(btc_txt)\n",
    "\n",
    "# Add a title to the document\n",
    "doc.user_data[\"title\"] = \"BTC NER\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Render the visualization\n",
    "displacy.render(doc, style='ent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all Entities\n",
    "for entity in doc.ents:\n",
    "    print(entity.text, entity.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ethereum NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all of the Ethereum text together\n",
    "eth_txt = eth_df.text.str.cat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the NER processor on all of the text\n",
    "doc1 = nlp(eth_txt)\n",
    "\n",
    "# Add a title to the document\n",
    "doc.user_data[\"title\"] = \"ETH NER\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Render the visualization\n",
    "displacy.render(doc1, style='ent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'doc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [32]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# List all Entities\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m entity1 \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdoc\u001b[49m\u001b[38;5;241m.\u001b[39ments:\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(entity1\u001b[38;5;241m.\u001b[39mtext, entity1\u001b[38;5;241m.\u001b[39mlabel_)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'doc' is not defined"
     ]
    }
   ],
   "source": [
    "# List all Entities\n",
    "for entity1 in doc.ents:\n",
    "    print(entity1.text, entity1.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
